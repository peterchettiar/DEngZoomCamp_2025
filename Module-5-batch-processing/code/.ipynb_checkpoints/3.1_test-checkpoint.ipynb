{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef8d9d4-967f-44f2-8cda-3b2eb94270b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11c75dbf-7850-46f6-8293-d984b84e5a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version of model\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b33f86-6766-453e-a952-b88fc05335bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/peter/spark/spark-3.5.5-bin-hadoop3/python/pyspark/__init__.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Location of model\n",
    "pyspark.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11744303-6b63-4e0b-960c-d470f0b05ae3",
   "metadata": {},
   "source": [
    "### Creating a Spark Session\n",
    "\n",
    "Initialising the spark object using the spark session classs is relatively straight-foraward:\n",
    "- `.getOrCreate()` : get the spark session if its already been created, or else create a new one based on `appName`\n",
    "- `.appName()` : Name of app\n",
    "- `.master()` : to define where and how spark runs its computations. `local[*]` means to run spark locally using all available CPU cores, this is particularly useful for testing given this is a demo session as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87390b0e-cf6f-4199-9325-08a3c9e84293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/10 13:43:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName('demo').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "037f5966-8735-418c-a739-1defc6f5e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading .csv file - spark does not know if there is header so it should be included in .options() method\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "002fdfa3-8815-4858-8fde-b7aa0815ca2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9146a0af-8d36-460b-9470-38929ea64b31",
   "metadata": {},
   "source": [
    "> **NOTE:** Output of the `.write.parquet()` method produces a folder in the current working directory, and in this folder there are two files, the first would be a `SUCCESS` file to indicate that the job was run successfully and the other file is the actual output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994056a4-dbb8-4673-a4cd-197cb80d9711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Now to output the dataframe as a .parquet file\n",
    "df.write.parquet('zones')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eefd75-c5eb-4e3a-8081-e08ddbc3d35a",
   "metadata": {},
   "source": [
    "> **IMPORTANT:** We need to forward another port `4040`. This is the default port for Spark which is a user interface for you to monitor your spark jobs. What we have done so far should have appeared there as well. Do check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c19d5d-55bf-4f5f-9abd-ba7746b5a577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
